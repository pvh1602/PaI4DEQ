{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitting as sp\n",
    "import train\n",
    "from pruning_utils.prune import *\n",
    "from pruning_utils.pruners import *\n",
    "from pruning_utils.generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnitude PaI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity is 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----tuning alpha----\n",
      "current:  1.0\n",
      "alpha: 1.0\t iters: 6\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 8\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 0.21 [12928/60000 (21%)]\tLoss: 2.2957\tError: 87.50\n",
      "Fwd iters: 6.00\tFwd Time: 0.0058\tBkwd Iters: 6.00\tBkwd Time: 0.0051\n",
      "\n",
      "Train Epoch: 0.43 [25728/60000 (43%)]\tLoss: 2.2961\tError: 86.72\n",
      "Fwd iters: 6.00\tFwd Time: 0.0059\tBkwd Iters: 6.00\tBkwd Time: 0.0051\n",
      "\n",
      "----tuning alpha----\n",
      "current:  0.5\n",
      "alpha: 1.0\t iters: 6\n",
      "alpha: 0.5\t iters: 6\n",
      "alpha: 0.25\t iters: 9\n",
      "setting to:  0.5\n",
      "--------------\n",
      "\n",
      "Train Epoch: 0.64 [38528/60000 (64%)]\tLoss: 2.3004\tError: 85.94\n",
      "Fwd iters: 6.00\tFwd Time: 0.0059\tBkwd Iters: 6.00\tBkwd Time: 0.0051\n",
      "\n",
      "Train Epoch: 0.85 [51328/60000 (85%)]\tLoss: 2.2994\tError: 89.84\n",
      "Fwd iters: 6.00\tFwd Time: 0.0060\tBkwd Iters: 6.00\tBkwd Time: 0.0050\n",
      "\n",
      "Tot train time: 13.237984418869019\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.3013, Error: 8865/10000 (88.65%)\n",
      "Tot test time: 1.2776570320129395\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainLoader, testLoader = train.mnist_loaders(train_batch_size=128, test_batch_size=400)\n",
    "\n",
    "model = train.SingleFcNet(sp.MONPeacemanRachford,\n",
    "                        in_dim=28**2,\n",
    "                        out_dim=87,\n",
    "                        alpha=1.0,\n",
    "                        max_iter=300,\n",
    "                        tol=1e-2,\n",
    "                        m=1.0,\n",
    "                        is_pruning=True)\n",
    "\n",
    "# print('Pruning with {} for {} epochs.'.format(args.pruner, args.prune_epochs))\n",
    "### Pruning\n",
    "masked_parameters_ = masked_parameters(model)\n",
    "pruner = Mag(masked_parameters_)\n",
    "\n",
    "###################################################\n",
    "####### Change compression to change the sparsity # \n",
    "###################################################\n",
    "compression = 1\n",
    "\n",
    "sparsity = 10**(-float(compression))\n",
    "print(f'sparsity is {1 - sparsity}')\n",
    "prune_loop(model, None, pruner, None, 'cpu', sparsity, schedule='exponential', scope='global', epochs=1,\n",
    "               reinitialize=False, train_mode=False, shuffle=False, invert=False,)\n",
    "\n",
    "### Training\n",
    "train.train(trainLoader, testLoader,\n",
    "            model,\n",
    "            max_lr=1e-3,\n",
    "            lr_mode='step',\n",
    "            step=10,\n",
    "            change_mo=False,\n",
    "            # epochs=40,\n",
    "            epochs=1,\n",
    "            print_freq=100,\n",
    "            tune_alpha=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model collapse because all parameters in the first layer are pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_kept / total params 0.0/68208 ~ (0.0000)\n",
      "n_kept / total params 87.0/87 ~ (100.0000)\n",
      "n_kept / total params 4184.0/7569 ~ (55.2781)\n",
      "n_kept / total params 4151.0/7569 ~ (54.8421)\n"
     ]
    }
   ],
   "source": [
    "for name, mask in model.named_buffers():\n",
    "    n_kept = mask.sum()\n",
    "    n_params = mask.numel()\n",
    "    \n",
    "    print('n_kept / total params {}/{} ~ ({:.4f})'.format(n_kept, n_params, n_kept/n_params*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleFcNet(\n",
       "  (mon): MONPeacemanRachford(\n",
       "    (linear_module): MaskedMONSingleFc(\n",
       "      (U): Linear(in_features=784, out_features=87, bias=True)\n",
       "      (A): Linear(in_features=87, out_features=87, bias=False)\n",
       "      (B): Linear(in_features=87, out_features=87, bias=False)\n",
       "    )\n",
       "    (nonlin_module): MONReLU()\n",
       "  )\n",
       "  (Wout): Linear(in_features=87, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random PaI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity is 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----tuning alpha----\n",
      "current:  1.0\n",
      "alpha: 1.0\t iters: 2\n",
      "alpha: 0.5\t iters: 5\n",
      "setting to:  1.0\n",
      "--------------\n",
      "\n",
      "Train Epoch: 0.21 [12928/60000 (21%)]\tLoss: 2.1763\tError: 51.56\n",
      "Fwd iters: 2.00\tFwd Time: 0.0047\tBkwd Iters: 3.00\tBkwd Time: 0.0029\n",
      "\n",
      "Train Epoch: 0.43 [25728/60000 (43%)]\tLoss: 1.7987\tError: 46.09\n",
      "Fwd iters: 2.00\tFwd Time: 0.0046\tBkwd Iters: 2.58\tBkwd Time: 0.0025\n",
      "\n",
      "----tuning alpha----\n",
      "current:  1.0\n",
      "alpha: 1.0\t iters: 2\n",
      "alpha: 0.5\t iters: 5\n",
      "setting to:  1.0\n",
      "--------------\n",
      "\n",
      "Train Epoch: 0.64 [38528/60000 (64%)]\tLoss: 1.4094\tError: 36.72\n",
      "Fwd iters: 2.00\tFwd Time: 0.0047\tBkwd Iters: 2.00\tBkwd Time: 0.0021\n",
      "\n",
      "Train Epoch: 0.85 [51328/60000 (85%)]\tLoss: 1.2550\tError: 36.72\n",
      "Fwd iters: 2.00\tFwd Time: 0.0048\tBkwd Iters: 2.00\tBkwd Time: 0.0020\n",
      "\n",
      "Tot train time: 11.461966753005981\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1365, Error: 3425/10000 (34.25%)\n",
      "Tot test time: 1.250028133392334\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainLoader, testLoader = train.mnist_loaders(train_batch_size=128, test_batch_size=400)\n",
    "\n",
    "model = train.SingleFcNet(sp.MONPeacemanRachford,\n",
    "                        in_dim=28**2,\n",
    "                        out_dim=87,\n",
    "                        alpha=1.0,\n",
    "                        max_iter=300,\n",
    "                        tol=1e-2,\n",
    "                        m=1.0,\n",
    "                        is_pruning=True)\n",
    "\n",
    "# print('Pruning with {} for {} epochs.'.format(args.pruner, args.prune_epochs))\n",
    "### Pruning\n",
    "masked_parameters_ = masked_parameters(model)\n",
    "pruner = Rand(masked_parameters_)\n",
    "\n",
    "###################################################\n",
    "####### Change compression to change the sparsity # \n",
    "###################################################\n",
    "compression = 3     \n",
    "\n",
    "sparsity = 10**(-float(compression))\n",
    "print(f'sparsity is {1 - sparsity}')\n",
    "prune_loop(model, None, pruner, None, 'cpu', sparsity, schedule='exponential', scope='global', epochs=1,\n",
    "               reinitialize=False, train_mode=False, shuffle=False, invert=False,)\n",
    "\n",
    "### Training\n",
    "train.train(trainLoader, testLoader,\n",
    "            model,\n",
    "            max_lr=1e-3,\n",
    "            lr_mode='step',\n",
    "            step=10,\n",
    "            change_mo=False,\n",
    "            # epochs=40,\n",
    "            epochs=1,\n",
    "            print_freq=100,\n",
    "            tune_alpha=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_kept / total params 76.0/68208 ~ (0.1114)\n",
      "n_kept / total params 87.0/87 ~ (100.0000)\n",
      "n_kept / total params 1.0/7569 ~ (0.0132)\n",
      "n_kept / total params 7.0/7569 ~ (0.0925)\n"
     ]
    }
   ],
   "source": [
    "for name, mask in model.named_buffers():\n",
    "    n_kept = mask.sum()\n",
    "    n_params = mask.numel()\n",
    "    \n",
    "    print('n_kept / total params {}/{} ~ ({:.4f})'.format(n_kept, n_params, n_kept/n_params*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  2,  2,  2,  2, 33,  3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,2,2,2,2,33,3])\n",
    "a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([33,  3,  2]),\n",
       "indices=tensor([6, 7, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(a,3, largest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.kthvalue(\n",
       "values=tensor(2),\n",
       "indices=tensor(5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.kthvalue(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4376586748096509"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 10**(-0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37d3f696be7176f0296fac589836b4846f5e3487b77d2b02a7aeb5b4aa5d52ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pvh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
